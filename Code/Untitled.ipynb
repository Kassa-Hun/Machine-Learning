{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "limited-reality",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_curve, roc_auc_score\n",
    "\n",
    "np.random.seed(42)\n",
    "hd=pd.read_csv('../Data/heart-disease.csv')\n",
    "hd.head();\n",
    "\n",
    "X=hd.drop(\"target\",axis=1)\n",
    "y=hd[\"target\"]\n",
    "\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "\n",
    "rfc=RandomForestClassifier()\n",
    "rfc.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "pleasant-norway",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8524590163934426, 0.8524590163934426, 0.8524590163934426)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds=rfc.predict(X_test)\n",
    "rfc.score(X_test,y_test), accuracy_score(y_test,y_preds), np.mean(y_test==y_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "encouraging-milton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.83      0.84        29\n",
      "           1       0.85      0.88      0.86        32\n",
      "\n",
      "    accuracy                           0.85        61\n",
      "   macro avg       0.85      0.85      0.85        61\n",
      "weighted avg       0.85      0.85      0.85        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(y_test,y_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "about-newport",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8524590163934426, 0.811639344262295)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.score(X_test,y_test), np.mean(cross_val_score(rfc, X, y, cv=5,scoring=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fifth-wheel",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob=rfc.predict_proba(X_test)\n",
    "y_prob_positive=y_prob[:,1]\n",
    "\n",
    "fpr,tpr,thresholds=roc_curve(y_test,y_prob_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "senior-infrastructure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## plot roc_curve \n",
    "\n",
    "def plot_roc_curve(fpr,tpr):\n",
    "    \n",
    "    plt.plot(fpr,tpr, color=\"orange\",label=\"ROC\")\n",
    "    plt.plot([0,1],[0,1],color=\"blue\",linestyle=\"dotted\", label=\"Guessing\")\n",
    "    plt.xlabel(\"FPR\")\n",
    "    plt.ylabel(\"TPR\")\n",
    "    plt.legend()\n",
    "    \n",
    "plot_roc_curve(fpr,tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "indian-barbados",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9304956896551724"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test,y_prob_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "passing-mortality",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Perfect AUC curve\n",
    "fpr,tpr,thresholds=roc_curve(y_test,y_test)\n",
    "plot_roc_curve(fpr,tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tired-pantyhose",
   "metadata": {},
   "source": [
    "## Confusion-matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "unlimited-hearing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[24,  5],\n",
       "       [ 4, 28]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds=rfc.predict(X_test)\n",
    "\n",
    "confusion_matrix(y_test,y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "excessive-buddy",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predict labels</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual labels</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predict labels   0   1\n",
       "Actual labels         \n",
       "0               24   5\n",
       "1                4  28"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_test,y_preds,\n",
    "           rownames=[\"Actual labels\"],\n",
    "           colnames=[\"Predict labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "revolutionary-intro",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAEACAYAAACatzzfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAUU0lEQVR4nO3da2xU17nG8WdssKHMjGPiFhTwvVFTQNAUywmJlIMwl04bEjkphGIRCrTCFFuNMaG0Qr1ITosJKKnt6FBkE0zbVMhtSGmKCzJVI4giVbFRpCo2KZ0RdhzRBk6rwY4Bj2efDzlwMhnjmbE97GX2/4f2B699W58evbx7zd4uy7IsAQCMlWL3BAAAIyOoAcBwBDUAGI6gBgDDEdQAYDiCGgAMN8nuCQz8tsbuKcAw93zzkN1TgKH+3Xd+TOcPXvLHfezkrIIx3Ws82R7UAHDbhIfsnsGoENQAnMMK2z2DUSGoAThHmKAGAKNZVNQAYLihkN0zGBWCGoBz8DARAAxH6wMADMfDRAAwGw8TAcB0VNQAYLihQbtnMCoENQDnoPUBAIaj9QEAhqOiBgDDUVEDgNmsMA8TAcBsVNQAYDh61ABgOF7KBACGo6IGAMMlqUcdDod15MgRvfLKK3r//fd19913q6SkRJWVlXK73ZKkZcuWqbu7O+rct956S9OnTx/x+gQ1AOdI0ocDGhsb9eKLL2rTpk1atGiRAoGA6urqdP78eTU1Nam/v189PT2qrq5WcXFxxLlerzfm9QlqAM6RhIrasiw1NjbqqaeeUnV1tSTpoYceUmZmpqqqqtTZ2amBgQFZlqWSkhIVFhYmfA+CGoBjWNb4P0zs7+/XY489Jp/PFzFeUFAgSeru7talS5eUnp6uvLy8Ud2DoAbgHEmoqN1ut3bt2hU13tbWJkn6/Oc/rzfffFN33XWXtm3bpjfffFNDQ0NavHixfvCDH+izn/1szHsQ1ACcI4FVH8FgUMFgMGrc6/XG7Cu/8847OnDggJYuXarCwkJ1dXXp0qVLuvfee7Vu3Tr5/X7V1dXp6aef1tGjRzVlypQRr0dQA3COBCrq5uZmNTQ0RI1XVFSosrLylue1t7ervLxcs2fPVk1NjSRp165dsixLCxYskCQVFRWpsLBQa9eu1bFjx7R69eoR50JQA3COBFZ9rF+/XqWlpVHjI1XTx48f186dO5WXl6fGxkZlZmZKkubPnx917MKFC+XxeNTV1RVzLgQ1AOdIoPURT4vjk15++WXV1taquLhYL730kjwejyTpo48+Umtrq+bOnav77rvv/6diWRocHLwZ5iNJiXsWADDRhcPxbwloaWnR7t275fP51NjYeDOkJSk9PV21tbVRbZRTp07p6tWrUeuqh0NFDcA5krDq4/Lly3ruuec0a9YslZWV6d13343Yn5OToy1btmj37t2qqanRkiVL9N5776m+vl4lJSV64IEHYt6DoAbgHEl418fp06c1MDCg3t5elZWVRe3fs2ePNmzYILfbrcOHD6ulpUUZGRlas2bNiA8lP8llWZY13hNPxMBva+y8PQx0zzcP2T0FGOrffefHdP7A7/fEfezUx3eM6V7jiYoagHPw4QAAMByvOQUAw1FRA4DhCGoAMJy9aydGjaAG4Byh5Hw4INkIagDOwcNEADAcPWoAMBw9agAwHBU1ABiOoAYAs1lD4/9x29uBoAbgHFTUAGA4lucBgOHCrPoAALPd6a2P3t5eBQIB9fX1KSUlRR6PR/n5+Zo5c2Yy5wcA4+dOfZh48uRJ/fznP5ff79enPwbjcrmUm5urZ555Rl/5yleSNkkAGBd3YkX92muvaefOnfL5fKqsrFRubq6mTZsmy7LU39+vCxcu6MSJE6qqqtLg4KBWrlx5u+YNAIm7E3vUBw4c0De+8Q396Ec/Gnb/nDlz5PP59OMf/1i/+MUvCGoAZpugqz5SRtrZ29urpUuXxrxISUmJenp6xm1SAJAUYSv+zSAjBnV2drbOnDkT8yJ/+ctfeKgIwHhWOBz3ZpIRWx/l5eV69tln9a9//UvLly9Xfn6+3G63XC6X+vr6bvaoX3/9df3kJz+5XXMGgNG5E1d9PProo0pNTdULL7ygP/7xj3K5XBH7LcvS7Nmz9dOf/lSlpaVJnSgAjJlhLY14xVye5/P55PP51NPTI7/fr76+PlmWdXMddU5Ozu2YJwCMnWEtjXjF/YOX7OxsZWdnJ3MuAJBcd2pFDQB3jAm6PI+gBuAcVNQAYDYrdAeu+gCAOwoVNQAYjh41ABiOihoAzGZN0KAe8V0fAHBHCQ3FvyUgHA7rN7/5jVauXKn7779fS5cu1c9+9jP19fXdPObMmTN68skntWDBAi1ZskQHDx6M+/pU1ACcI0kVdWNjo1588UVt2rRJixYtUiAQUF1dnc6fP6+mpiZ1dHSovLxcPp9P3/3ud9Xe3q49e/bIsixt2rQp5vUJagDOkYSgtixLjY2Neuqpp1RdXS1Jeuihh5SZmamqqip1dnaqrq5Oc+bM0fPPPy9JeuSRRxQKhbR//36tW7dOaWlpI96D1gcAx7AsK+4tXv39/Xrsscf06KOPRowXFBRIkv7+97/r7bff1vLlyyP2r1ixQsFgUB0dHTHvQUUNwDkSqKiDwaCCwWDUuNfrldfrvfm32+3Wrl27oo5ra2uT9PGXsAYHB5Wfnx+xPzc3V5IUCAT04IMPjjgXghqAcyQQ1M3NzWpoaIgar6ioUGVl5YjnvvPOOzpw4ICWLl2qK1euSPo40D9p2rRpkhTxwPFWCGoAjmGF4v/By/r164d9z/4nq+nhtLe3q7y8XLNnz1ZNTY0CgYAkRb3P/4aUlNgdaIIagHMk8MPET7c44nH8+HHt3LlTeXl5amxsVGZmpi5duiQpunK+8bfH44l5XR4mAnAMK2zFvSXq5Zdf1rZt2/SlL31Jv/71r/W5z31OkpSTk6PU1FR1d3dHHH/j70/3rodDUANwjiR9hbylpUW7d++Wz+dTY2NjRJWcnp6uoqIinTx5MmI1yYkTJ+TxeDRv3ryY16f1AcA5kvBOpsuXL+u5557TrFmzVFZWpnfffTdif05OjrZs2aINGzaoqqpKpaWlOnv2rJqamlRdXa2pU6fGvAdBDcAxkvGuj9OnT2tgYEC9vb0qKyuL2r9nzx49/vjjqq+vV11dnbZu3aoZM2Zox44d2rhxY1z3cFmJrOxOgoHf1th5exjonm8esnsKMNS/+86P6fz/Kf2vuI+dfvSNMd1rPFFRA3COifk6aoIagHNM0O8GENQAHISgBgCzUVEDgOGskN0zGB2CGoBjUFEDgOEIagAwnTX8G+xMR1ADcAwqagAwnBWmogYAo4WHCGoAMBqtDwAwHK0PADCcve8KHT2CGoBjUFEDgOF4mAgAhqOiBgDDWfwyEQDMxvI8ADBcmIoaAMxG6wMADMeqDwAwHKs+AMBw9KgBwHD0qAHAcLzrAwAMR+sDAAwX5mHi6HjW/rfdU4BhBj44bfcUcIeiogYAw/EwEQAMR0UNAIaboIs+CGoAzjEUTkn6PTo7O/X1r39dp06d0syZM2+OL1u2TN3d3VHHv/XWW5o+ffqI1ySoAThGst9y6vf7tXnzZoVCoYjx/v5+9fT0qLq6WsXFxRH7vF5vzOsS1AAcw1JyetShUEhHjhzRvn37NHny5Kj9586dk2VZKikpUWFhYcLXT/7/AwDAEGEr/i0R7e3t2rt3rzZu3Kjt27dH7e/s7FR6erry8vJGNW+CGoBjhOWKe0tEYWGh2traVFFRodTU1Kj9586d01133aVt27apqKhI999/v6qqqvThhx/GdX1aHwAcI5HWRzAYVDAYjBr3er1RfeWsrKwRr9XV1aVLly7p3nvv1bp16+T3+1VXV6enn35aR48e1ZQpU0Y8n6AG4BhDCQR1c3OzGhoaosYrKipUWVmZ0H137doly7K0YMECSVJRUZEKCwu1du1aHTt2TKtXrx7xfIIagGMksupj/fr1Ki0tjRqPZ5XGp82fPz9qbOHChfJ4POrq6op5PkENwDESCerhWhyj8dFHH6m1tVVz587Vfffdd3PcsiwNDg4qMzMz5jV4mAjAMSy54t7GS3p6umpra6PaKKdOndLVq1ej1lUPh4oagGPY8ZbT1NRUbdmyRbt371ZNTY2WLFmi9957T/X19SopKdEDDzwQ8xoENQDHSHTZ3XjZsGGD3G63Dh8+rJaWFmVkZGjNmjVxP5R0WZa9H6eZlDbLztvDQLyPGrcyOatgTOe/OnNt3Mc+cfGVMd1rPFFRA3CMsIvXnAKA0XjNKQAYLtlvz0sWghqAY0zQb9sS1ACcI5GfkJuEoAbgGFTUAGA4etQAYDhWfQCA4Wh9AIDhaH0AgOGGqKgBwGxU1ABgOIIaAAzHqg8AMByrPgDAcLQ+AMBwQ3ZPYJQIagCOQesDAAxH6wMADMeqDwAwXHiCRjVBDcAxeJgIAIajRw0AhmPVBwAYjh41ABhuYsY0QQ3AQehRA4DhhiZoTU1QA3AMKmoAMBwPEwHAcBMzpglqAA4yUVsfKXZPAABulyFZcW+j1dnZqblz5+rixYsR42fOnNGTTz6pBQsWaMmSJTp48GDc1ySoAThGWFbc22j4/X5t3rxZoVAoYryjo0Pl5eUqKChQfX29Vq5cqT179qipqSmu69L6AOAYyepRh0IhHTlyRPv27dPkyZOj9tfV1WnOnDl6/vnnJUmPPPKIQqGQ9u/fr3Xr1iktLW3E61NRA3CMZFXU7e3t2rt3rzZu3Kjt27dH7Lt27ZrefvttLV++PGJ8xYoVCgaD6ujoiHn9mBX1P//5z4QmPGPGjISOB4DbJVkPEwsLC9XW1qa7775br776asS+np4eDQ4OKj8/P2I8NzdXkhQIBPTggw+OeP2YQV1SUqKhofjf4trZ2Rn3sQBwO1kJVMrBYFDBYDBq3Ov1yuv1RoxlZWXd8jpXrlyRJLnd7ojxadOmSZL6+vpiziVmULe0tGjz5s26fv26qqurNWkSbW0AE1Miqzmam5vV0NAQNV5RUaHKysq4r2NZH9/T5Rr+HaspKbE70DFT94tf/KIOHTqkVatW6cMPP9R3vvOduCcIACZJpPWxfv16lZaWRo1/upqOxePxSIqunG/8fWP/SOIqjwsKCrRt2zbt27dPa9as0fTp0xOaKACYIGzFX1EP1+IYjZycHKWmpqq7uzti/Mbfn+5dDyfuVR9r1qzR/v37E5wiAJjDSmAbL+np6SoqKtLJkydvtkEk6cSJE/J4PJo3b17Ma8TdcE5NTVVxcfHoZgoABrDrpUxbtmzRhg0bVFVVpdLSUp09e1ZNTU2qrq7W1KlTY57POmoAjmEl8G88LVq0SPX19frHP/6hrVu36g9/+IN27Nihb3/723Gd77KsBJo2STApbZadt4eBBj44bfcUYKjJWQVjOn9V7uNxH9ty4fdjutd4Yq0dAMcY70r5diGoATjGRH3NKUENwDFs7vSOGkENwDH4FBcAGI6vkAOA4aioAcBw9KgBwHCs+gAAw7GOGgAMR48aAAw3ZE3M5gdBDcAxaH0AgOES+XCASQhqAI4xMWOaoAbgIDxMBADDEdQAYDhWfQCA4Vj1AQCG410fAGA4etQAYDgqagAw3NAEfX8eQQ3AMfhlIgAYjlUfAGA4KmoAMBwVNQAYjooaAAzHT8gBwHC0PgDAcBYVNQCYjZ+QA4Dh+Ak5ABiOihoADDcUTk6POhQK6ctf/rKuXbsWMf6Zz3xGZ8+eHfP1CWoAjpGsVR+BQEDXrl1TbW2t8vLybo6npKSMy/UJagCOkawedVdXl1JSUrRixQpNnTp13K9PUANwjGT1qDs7O5WTk5OUkJYIagAOkkhFHQwGFQwGo8a9Xq+8Xm/E2Llz55SWlqZNmzapo6NDkyZNks/n044dO+R2u8c8b4IagGMk8jCxublZDQ0NUeMVFRWqrKyMGOvq6lJfX59WrVql8vJy/e1vf1N9fb0CgYAOHz4sl8s1pnm7LJsXFk5Km2Xn7WGggQ9O2z0FGGpyVsGYzs9wF8Z9bM8HZ+OuqP/6178qIyNDX/jCF26OHTt2TM8++6wOHjyohx9+ePSTFhU1AAdJpC4dLpBvpbi4OGps8eLFkj6utsca1OOzdgQAJoCwZcW9xevy5ctqaWlRT09PxPjVq1clSZmZmWOeN0ENwDGsBP7Fy+Vy6Yc//KF+9atfRYwfP35cqampWrhw4ZjnTesDgGMk48MB06dPV1lZmX75y1/K7XarqKhI7e3t2r9/v8rKypSbmzvme/AwEcbhYSJuZawPE9OnZMd97LWrPbEP+j+Dg4M6dOiQfve736m3t1czZszQ6tWr9a1vfWtcfp1IUMM4BDVuZaxBnZY+O+5jr197f0z3Gk+0PgA4xkR9zantFTUAYGSs+gAAwxHUAGA4ghoADEdQA4DhCGoAMBxBDQCGI6gBwHAENQAYjqAGAMMR1AZ4/fXX9bWvfU3z58+Xz+fTa6+9ZveUYJDOzk7NnTtXFy9etHsqsAlBbbPW1lZt375dDz/8sF566SUVFxfre9/7nv70pz/ZPTUYwO/3a/PmzQqFQnZPBTbiXR82W7ZsmebNm6cXXnjh5tgzzzyjc+fOqbW11caZwU6hUEhHjhzRvn37NHnyZP3nP//RG2+8oZkzZ9o9NdiAitpGPT096u7u1vLlyyPGV6xYIb/fH/VpHzhHe3u79u7dq40bN2r79u12Twc2I6ht5Pf7JUn5+fkR4ze+CBEIBG77nGCGwsJCtbW1qaKiQqmpqXZPBzbjfdQ2unLliiTJ7XZHjE+bNk2S1NfXd9vnBDNkZWXZPQUYhIraRjceD7hcrmHHx+MTPgAmPpLARh6PR1J05dzf3x+xH4CzEdQ2utGb7u7ujhi/cOFCxH4AzkZQ2yg3N1ezZ8+OWjN98uRJ5eXl6Z577rFpZgBMwsNEm23dulXf//73lZGRocWLF+vPf/6zWltbI9ZVA3A2gtpmTzzxhK5fv66DBw+qpaVF2dnZqq2t1Ve/+lW7pwbAEPwyEQAMR48aAAxHUAOA4QhqADAcQQ0AhiOoAcBwBDUAGI6gBgDDEdQAYDiCGgAM979OgqVSTjo5SQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(font_scale=1.5)\n",
    "conf_mat=confusion_matrix(y_test,y_preds)\n",
    "\n",
    "sns.heatmap(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "wanted-insulation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_conf_mat(conf_mat):\n",
    "    fig,ax=plt.subplots(figsize=(3,3))\n",
    "    ax=sns.heatmap(conf_mat,\n",
    "                  annot=True,\n",
    "                  cbar=False)\n",
    "    plt.xlabel(\"True label\")\n",
    "    plt.ylabel(\"Predicted label\")\n",
    "\n",
    "\n",
    "plot_conf_mat(conf_mat)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "located-vitamin",
   "metadata": {},
   "source": [
    "**Classification report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "above-review",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.83      0.84        29\n",
      "           1       0.85      0.88      0.86        32\n",
      "\n",
      "    accuracy                           0.85        61\n",
      "   macro avg       0.85      0.85      0.85        61\n",
      "weighted avg       0.85      0.85      0.85        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "worldwide-devices",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\sample_project_1\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.99990</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.499950</td>\n",
       "      <td>0.99980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.99990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.99995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.499975</td>\n",
       "      <td>0.99985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>9999.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0.0  1.0  accuracy     macro avg  weighted avg\n",
       "precision     0.99990  0.0    0.9999      0.499950       0.99980\n",
       "recall        1.00000  0.0    0.9999      0.500000       0.99990\n",
       "f1-score      0.99995  0.0    0.9999      0.499975       0.99985\n",
       "support    9999.00000  1.0    0.9999  10000.000000   10000.00000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disease_true=np.zeros(10000)\n",
    "disease_true[0]=1\n",
    "\n",
    "disease_preds=np.zeros(10000)\n",
    "\n",
    "pd.DataFrame(classification_report(disease_true,\n",
    "                                  disease_preds,\n",
    "                                  output_dict=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "global-sapphire",
   "metadata": {},
   "source": [
    "### Regression model evaluation metrics\n",
    "\n",
    "1. R^2 -Coefficient of determination\n",
    "2. Mean absolute error (MAE)\n",
    "3. Mean square error (MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structural-coaching",
   "metadata": {},
   "source": [
    "**R^2**\n",
    "* Compares your models predictions to the mean of the target.\n",
    "* values can range from -ve infinity (a very ppot model) to 1. For example, if all your model does is the mean of the targets, it's R^2 value would be 0. And if your model perfectly predicts a range of numbers it's value would be 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "parental-germany",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8654448653350507"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "boston=load_boston()\n",
    "\n",
    "boston_df=pd.DataFrame(boston[\"data\"],columns=boston[\"feature_names\"])\n",
    "boston_df[\"target\"]=boston[\"target\"]\n",
    "\n",
    "X=boston_df.drop(\"target\",axis=1)\n",
    "y=boston_df[\"target\"]\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "model=RandomForestRegressor()\n",
    "model.fit(X_train,y_train);\n",
    "\n",
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "sonic-thanks",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.488235294117644"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "# Fill an array with y_test mean\n",
    "\n",
    "y_test_mean=np.full(len(y_test),y_test.mean())\n",
    "y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "compound-amazon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " r2_score(y_test,y_test_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fifty-chorus",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "automated-fisher",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "living-firmware",
   "metadata": {},
   "source": [
    "**MAE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "indian-addition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.136382352941176"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "mae=mean_absolute_error(y_test,y_preds)\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "southwest-bangkok",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual values</th>\n",
       "      <th>Predicted values</th>\n",
       "      <th>Differences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>23.6</td>\n",
       "      <td>23.081</td>\n",
       "      <td>0.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>32.4</td>\n",
       "      <td>30.574</td>\n",
       "      <td>1.826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>13.6</td>\n",
       "      <td>16.759</td>\n",
       "      <td>-3.159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>22.8</td>\n",
       "      <td>23.460</td>\n",
       "      <td>-0.660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>16.1</td>\n",
       "      <td>16.893</td>\n",
       "      <td>-0.793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>17.9</td>\n",
       "      <td>13.159</td>\n",
       "      <td>4.741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>9.6</td>\n",
       "      <td>12.476</td>\n",
       "      <td>-2.876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>17.2</td>\n",
       "      <td>13.612</td>\n",
       "      <td>3.588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>22.5</td>\n",
       "      <td>20.205</td>\n",
       "      <td>2.295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>21.4</td>\n",
       "      <td>23.832</td>\n",
       "      <td>-2.432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Actual values  Predicted values  Differences\n",
       "173           23.6            23.081        0.519\n",
       "274           32.4            30.574        1.826\n",
       "491           13.6            16.759       -3.159\n",
       "72            22.8            23.460       -0.660\n",
       "452           16.1            16.893       -0.793\n",
       "..             ...               ...          ...\n",
       "412           17.9            13.159        4.741\n",
       "436            9.6            12.476       -2.876\n",
       "411           17.2            13.612        3.588\n",
       "86            22.5            20.205        2.295\n",
       "75            21.4            23.832       -2.432\n",
       "\n",
       "[102 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame(data={\"Actual values\":y_test,\n",
    "                      \"Predicted values\":y_preds})\n",
    "df[\"Differences\"]=df[\"Actual values\"]-df[\"Predicted values\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "associate-alliance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.136382352941176, 2.136382352941176)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test,y_preds), sum(abs(df[\"Differences\"]))/len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statutory-hypothetical",
   "metadata": {},
   "source": [
    "### MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "prescribed-holly",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.867437068627442"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse=mean_squared_error(y_test,y_preds)\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "sophisticated-floating",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9.867437068627442, 9.867437068627442)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse, np.square(df[\"Differences\"]).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generous-spare",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "* Accuracy\n",
    "* Precision\n",
    "* Recall\n",
    "* F1 score\n",
    "\n",
    "# Regression\n",
    "\n",
    "* R^2\n",
    "* MAE\n",
    "* MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "portable-characterization",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7704918032786885,\n",
       " 0.7704918032786885,\n",
       " 0.7352941176470589,\n",
       " 0.8333333333333334,\n",
       " 0.78125)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classification\n",
    "from sklearn.metrics import accuracy_score,precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X=hd.drop(\"target\",axis=1)\n",
    "y=hd[\"target\"]\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "model=RandomForestClassifier()\n",
    "\n",
    "model.fit(X_train,y_train);\n",
    "y_preds=model.predict(X_test)\n",
    "\n",
    "model.score(X_test,y_test), accuracy_score(y_test,y_preds), precision_score(y_test,y_preds), recall_score(y_test,y_preds),f1_score(y_test,y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "burning-miller",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.42792578828828853, 0.2434426229508197, 0.13652295081967208)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regression\n",
    "from sklearn.metrics import r2_score,mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "X=hd.drop(\"target\",axis=1)\n",
    "y=hd[\"target\"]\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "model=RandomForestRegressor()\n",
    "\n",
    "model.fit(X_train,y_train);\n",
    "y_preds=model.predict(X_test)\n",
    "\n",
    "r2_score(y_test,y_preds), mean_absolute_error(y_test,y_preds), mean_squared_error(y_test,y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raised-amplifier",
   "metadata": {},
   "source": [
    "## 5. Improving a model\n",
    "\n",
    "From a data perspective:\n",
    "\n",
    "   * Could we collect more data? \n",
    "   * Could we improve our data?\n",
    "    \n",
    "From a model perspectve:\n",
    "\n",
    "   * IS there a better model we could use?\n",
    "   * Could we improve the current model?\n",
    "\n",
    "Hyperparameters vs. Parameters\n",
    "\n",
    "* Parameters - model find these patterns in data\n",
    "* Hyperparameter - settings on a model you can adjust to improve its ability to find patterns\n",
    "\n",
    "Three ways to adjust hyperparameters:\n",
    "   1. By hand\n",
    "   2. Randomly - RandomSearchCV\n",
    "   3. Exhaustively - GridSearchCV\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "veterinary-university",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model=RandomForestClassifier()\n",
    "model.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuffed-organic",
   "metadata": {},
   "source": [
    "#### 5.1 Tuning hyperparameters by hand\n",
    "\n",
    "Let's make 3 sets: training,validation and test\n",
    "\n",
    "We're going to try and adjust:\n",
    "\n",
    "* 'max_depth'\n",
    "* 'max_features'\n",
    "* 'min_samples_leaf'\n",
    "* 'min_samples_split'\n",
    "* 'n_estimators'\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "muslim-smell",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_preds(y_true,y_preds):\n",
    "    \n",
    "    accuracy=accuracy_score(y_true,y_preds)\n",
    "    precision=precision_score(y_true,y_preds)\n",
    "    recall=recall_score(y_true,y_preds)\n",
    "    f1=f1_score(y_true,y_preds)\n",
    "    metrics_dict={\"accuracy\":round(accuracy,2),\n",
    "                  \"precision\":round(precision,2),\n",
    "                  \"recall\":round(recall,2),\n",
    "                  \"f1\":round(f1,2)\n",
    "                 }\n",
    "    print (f\"Accu: {accuracy * 100:.2f}%\")\n",
    "    print (f\"Precision: {precision:.2f}\")\n",
    "    print (f\"Recall: {recall:.2f}\")\n",
    "    print (f\"F1 score: {f1:.2f}\")\n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "brown-uncle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accu: 82.22%\n",
      "Precision: 0.81\n",
      "Recall: 0.88\n",
      "F1 score: 0.85\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.82, 'precision': 0.81, 'recall': 0.88, 'f1': 0.85}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Shuffle datasets\n",
    "hds=hd.sample(frac=1)\n",
    "\n",
    "X=hds.drop(\"target\",axis=1)\n",
    "y=hds[\"target\"]\n",
    "\n",
    "# train, validation and test split\n",
    "\n",
    "train_split=round(0.7 * len(hds))\n",
    "valid_split=round(train_split+0.15*len(hds))\n",
    "\n",
    "X_train,y_train=X[:train_split], y[:train_split]\n",
    "X_valid,y_valid=X[train_split:valid_split],y[train_split:valid_split]\n",
    "X_test,y_test=X[valid_split:],y[valid_split:]\n",
    "\n",
    "#len(X_train), len(X_valid), len(X_test)\n",
    "\n",
    "clf=RandomForestClassifier()\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "#Make baseline prediction\n",
    "y_preds=clf.predict(X_valid)\n",
    "\n",
    "#Evaluate the classifier on validation set\n",
    "baseline_metrics=evaluate_preds(y_valid,y_preds)\n",
    "baseline_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "worthy-lyric",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accu: 71.11%\n",
      "Precision: 0.75\n",
      "Recall: 0.72\n",
      "F1 score: 0.73\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.71, 'precision': 0.75, 'recall': 0.72, 'f1': 0.73}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "#Create a 2nd classifier with d/t hyperparameters\n",
    "clf_2=RandomForestClassifier(n_estimators=1)\n",
    "clf_2.fit(X_train,y_train)\n",
    "y_preds_2=clf_2.predict(X_valid)\n",
    "\n",
    "evaluate_preds(y_valid,y_preds_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "electoral-messaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf_3=RandomForestClassifier(max_depth=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dramatic-daniel",
   "metadata": {},
   "source": [
    "### RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "partial-giant",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] n_estimators=1, min_sample_split=2, min_sample_leaf=4, max_features=auto, max_depth=5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter min_sample_split for estimator RandomForestClassifier(n_estimators=1). Check the list of available parameters with `estimator.get_params().keys()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-4eacf98431c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m                          verbose=3)\n\u001b[0;32m     27\u001b[0m \u001b[1;31m# Fit the RandomizedSearchCV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mrs_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\sample_project_1\\env\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\sample_project_1\\env\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    734\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\sample_project_1\\env\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1527\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1528\u001b[0m         \u001b[1;34m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1529\u001b[1;33m         evaluate_candidates(ParameterSampler(\n\u001b[0m\u001b[0;32m   1530\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1531\u001b[0m             random_state=self.random_state))\n",
      "\u001b[1;32mE:\\sample_project_1\\env\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    706\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 708\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    709\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\sample_project_1\\env\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1039\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1040\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1041\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\sample_project_1\\env\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    857\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\sample_project_1\\env\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 777\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    778\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\sample_project_1\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\sample_project_1\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\sample_project_1\\env\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\sample_project_1\\env\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\sample_project_1\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    518\u001b[0m             \u001b[0mcloned_parameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 520\u001b[1;33m         \u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mcloned_parameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    521\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\sample_project_1\\env\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mset_params\u001b[1;34m(self, **params)\u001b[0m\n\u001b[0;32m    247\u001b[0m             \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msub_key\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvalid_params\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m                 raise ValueError('Invalid parameter %s for estimator %s. '\n\u001b[0m\u001b[0;32m    250\u001b[0m                                  \u001b[1;34m'Check the list of available parameters '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m                                  \u001b[1;34m'with `estimator.get_params().keys()`.'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid parameter min_sample_split for estimator RandomForestClassifier(n_estimators=1). Check the list of available parameters with `estimator.get_params().keys()`."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Create your own dictionary\n",
    "\n",
    "grid={\"n_estimators\":[1, 100,200,500,1000,1200],\n",
    "      \"max_depth\":[None,5,10,20,30],\n",
    "      \"max_features\":[\"auto\",\"sqrt\"],\n",
    "      \"min_sample_split\":[2,4,6],\n",
    "      \"min_sample_leaf\":[1,2,4]\n",
    "     }\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "np.random.seed(42)\n",
    "\n",
    "X=hds.drop(\"target\",axis=1)\n",
    "y=hds[\"target\"]\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "clf_3=RandomForestClassifier(n_jobs=1) #-1 all processors\n",
    "\n",
    "#Setup RandomizedSearchCV\n",
    "\n",
    "rs_clf=RandomizedSearchCV(estimator=clf_3,\n",
    "                         param_distributions=grid,\n",
    "                         n_iter=10,\n",
    "                         cv=5,\n",
    "                         verbose=3)\n",
    "# Fit the RandomizedSearchCV\n",
    "rs_clf.fit(X_train,y_train);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "correct-fountain",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomizedSearchCV' object has no attribute 'best_scores_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-861fa9566a75>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrs_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_scores_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'RandomizedSearchCV' object has no attribute 'best_scores_'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "satellite-checklist",
   "metadata": {},
   "source": [
    "### GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "hybrid-heritage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] max_depth=None, max_features=auto, min_sample_leaf=1, min_sample_split=6, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter min_sample_leaf for estimator RandomForestClassifier(n_jobs=1). Check the list of available parameters with `estimator.get_params().keys()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-06ba352343a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m                          verbose=3)\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# Fit the GridSearchCV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mgs_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\sample_project_1\\env\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\sample_project_1\\env\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    734\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\sample_project_1\\env\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1188\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\sample_project_1\\env\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    706\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 708\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    709\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\sample_project_1\\env\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1039\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1040\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1041\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\sample_project_1\\env\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    857\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\sample_project_1\\env\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 777\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    778\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\sample_project_1\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\sample_project_1\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\sample_project_1\\env\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\sample_project_1\\env\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\sample_project_1\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    518\u001b[0m             \u001b[0mcloned_parameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 520\u001b[1;33m         \u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mcloned_parameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    521\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\sample_project_1\\env\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mset_params\u001b[1;34m(self, **params)\u001b[0m\n\u001b[0;32m    247\u001b[0m             \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msub_key\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvalid_params\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m                 raise ValueError('Invalid parameter %s for estimator %s. '\n\u001b[0m\u001b[0;32m    250\u001b[0m                                  \u001b[1;34m'Check the list of available parameters '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m                                  \u001b[1;34m'with `estimator.get_params().keys()`.'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid parameter min_sample_leaf for estimator RandomForestClassifier(n_jobs=1). Check the list of available parameters with `estimator.get_params().keys()`."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "grid2={'n_estimators': [100, 200, 500],\n",
    "       'max_depth': [None],\n",
    "       'max_features': ['auto', 'sqrt'],\n",
    "       'min_sample_split': [6],\n",
    "       'min_sample_leaf': [1, 2]}\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X=hds.drop(\"target\",axis=1)\n",
    "y=hds[\"target\"]\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "clf_4=RandomForestClassifier(n_jobs=1) #-1 all processors\n",
    "\n",
    "#Setup GridSearchCV\n",
    "\n",
    "gs_clf=GridSearchCV(estimator=clf_4,\n",
    "                         param_grid=grid2,\n",
    "                         cv=5,\n",
    "                         verbose=3)\n",
    "# Fit the GridSearchCV\n",
    "gs_clf.fit(X_train,y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "indirect-pressing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.098447</td>\n",
       "      <td>-0.068653</td>\n",
       "      <td>0.279351</td>\n",
       "      <td>0.213678</td>\n",
       "      <td>0.121308</td>\n",
       "      <td>-0.116211</td>\n",
       "      <td>-0.398522</td>\n",
       "      <td>0.096801</td>\n",
       "      <td>0.210013</td>\n",
       "      <td>-0.168814</td>\n",
       "      <td>0.276326</td>\n",
       "      <td>0.068001</td>\n",
       "      <td>-0.225439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>-0.098447</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.049353</td>\n",
       "      <td>-0.056769</td>\n",
       "      <td>-0.197912</td>\n",
       "      <td>0.045032</td>\n",
       "      <td>-0.058196</td>\n",
       "      <td>-0.044020</td>\n",
       "      <td>0.141664</td>\n",
       "      <td>0.096093</td>\n",
       "      <td>-0.030711</td>\n",
       "      <td>0.118261</td>\n",
       "      <td>0.210041</td>\n",
       "      <td>-0.280937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cp</th>\n",
       "      <td>-0.068653</td>\n",
       "      <td>-0.049353</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.047608</td>\n",
       "      <td>-0.076904</td>\n",
       "      <td>0.094444</td>\n",
       "      <td>0.044421</td>\n",
       "      <td>0.295762</td>\n",
       "      <td>-0.394280</td>\n",
       "      <td>-0.149230</td>\n",
       "      <td>0.119717</td>\n",
       "      <td>-0.181053</td>\n",
       "      <td>-0.161736</td>\n",
       "      <td>0.433798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trestbps</th>\n",
       "      <td>0.279351</td>\n",
       "      <td>-0.056769</td>\n",
       "      <td>0.047608</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.123174</td>\n",
       "      <td>0.177531</td>\n",
       "      <td>-0.114103</td>\n",
       "      <td>-0.046698</td>\n",
       "      <td>0.067616</td>\n",
       "      <td>0.193216</td>\n",
       "      <td>-0.121475</td>\n",
       "      <td>0.101389</td>\n",
       "      <td>0.062210</td>\n",
       "      <td>-0.144931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chol</th>\n",
       "      <td>0.213678</td>\n",
       "      <td>-0.197912</td>\n",
       "      <td>-0.076904</td>\n",
       "      <td>0.123174</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013294</td>\n",
       "      <td>-0.151040</td>\n",
       "      <td>-0.009940</td>\n",
       "      <td>0.067023</td>\n",
       "      <td>0.053952</td>\n",
       "      <td>-0.004038</td>\n",
       "      <td>0.070511</td>\n",
       "      <td>0.098803</td>\n",
       "      <td>-0.085239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fbs</th>\n",
       "      <td>0.121308</td>\n",
       "      <td>0.045032</td>\n",
       "      <td>0.094444</td>\n",
       "      <td>0.177531</td>\n",
       "      <td>0.013294</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.084189</td>\n",
       "      <td>-0.008567</td>\n",
       "      <td>0.025665</td>\n",
       "      <td>0.005747</td>\n",
       "      <td>-0.059894</td>\n",
       "      <td>0.137979</td>\n",
       "      <td>-0.032019</td>\n",
       "      <td>-0.028046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>restecg</th>\n",
       "      <td>-0.116211</td>\n",
       "      <td>-0.058196</td>\n",
       "      <td>0.044421</td>\n",
       "      <td>-0.114103</td>\n",
       "      <td>-0.151040</td>\n",
       "      <td>-0.084189</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.044123</td>\n",
       "      <td>-0.070733</td>\n",
       "      <td>-0.058770</td>\n",
       "      <td>0.093045</td>\n",
       "      <td>-0.072042</td>\n",
       "      <td>-0.011981</td>\n",
       "      <td>0.137230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thalach</th>\n",
       "      <td>-0.398522</td>\n",
       "      <td>-0.044020</td>\n",
       "      <td>0.295762</td>\n",
       "      <td>-0.046698</td>\n",
       "      <td>-0.009940</td>\n",
       "      <td>-0.008567</td>\n",
       "      <td>0.044123</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.378812</td>\n",
       "      <td>-0.344187</td>\n",
       "      <td>0.386784</td>\n",
       "      <td>-0.213177</td>\n",
       "      <td>-0.096439</td>\n",
       "      <td>0.421741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exang</th>\n",
       "      <td>0.096801</td>\n",
       "      <td>0.141664</td>\n",
       "      <td>-0.394280</td>\n",
       "      <td>0.067616</td>\n",
       "      <td>0.067023</td>\n",
       "      <td>0.025665</td>\n",
       "      <td>-0.070733</td>\n",
       "      <td>-0.378812</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.288223</td>\n",
       "      <td>-0.257748</td>\n",
       "      <td>0.115739</td>\n",
       "      <td>0.206754</td>\n",
       "      <td>-0.436757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oldpeak</th>\n",
       "      <td>0.210013</td>\n",
       "      <td>0.096093</td>\n",
       "      <td>-0.149230</td>\n",
       "      <td>0.193216</td>\n",
       "      <td>0.053952</td>\n",
       "      <td>0.005747</td>\n",
       "      <td>-0.058770</td>\n",
       "      <td>-0.344187</td>\n",
       "      <td>0.288223</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.577537</td>\n",
       "      <td>0.222682</td>\n",
       "      <td>0.210244</td>\n",
       "      <td>-0.430696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slope</th>\n",
       "      <td>-0.168814</td>\n",
       "      <td>-0.030711</td>\n",
       "      <td>0.119717</td>\n",
       "      <td>-0.121475</td>\n",
       "      <td>-0.004038</td>\n",
       "      <td>-0.059894</td>\n",
       "      <td>0.093045</td>\n",
       "      <td>0.386784</td>\n",
       "      <td>-0.257748</td>\n",
       "      <td>-0.577537</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.080155</td>\n",
       "      <td>-0.104764</td>\n",
       "      <td>0.345877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca</th>\n",
       "      <td>0.276326</td>\n",
       "      <td>0.118261</td>\n",
       "      <td>-0.181053</td>\n",
       "      <td>0.101389</td>\n",
       "      <td>0.070511</td>\n",
       "      <td>0.137979</td>\n",
       "      <td>-0.072042</td>\n",
       "      <td>-0.213177</td>\n",
       "      <td>0.115739</td>\n",
       "      <td>0.222682</td>\n",
       "      <td>-0.080155</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.151832</td>\n",
       "      <td>-0.391724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thal</th>\n",
       "      <td>0.068001</td>\n",
       "      <td>0.210041</td>\n",
       "      <td>-0.161736</td>\n",
       "      <td>0.062210</td>\n",
       "      <td>0.098803</td>\n",
       "      <td>-0.032019</td>\n",
       "      <td>-0.011981</td>\n",
       "      <td>-0.096439</td>\n",
       "      <td>0.206754</td>\n",
       "      <td>0.210244</td>\n",
       "      <td>-0.104764</td>\n",
       "      <td>0.151832</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.344029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>-0.225439</td>\n",
       "      <td>-0.280937</td>\n",
       "      <td>0.433798</td>\n",
       "      <td>-0.144931</td>\n",
       "      <td>-0.085239</td>\n",
       "      <td>-0.028046</td>\n",
       "      <td>0.137230</td>\n",
       "      <td>0.421741</td>\n",
       "      <td>-0.436757</td>\n",
       "      <td>-0.430696</td>\n",
       "      <td>0.345877</td>\n",
       "      <td>-0.391724</td>\n",
       "      <td>-0.344029</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age       sex        cp  trestbps      chol       fbs  \\\n",
       "age       1.000000 -0.098447 -0.068653  0.279351  0.213678  0.121308   \n",
       "sex      -0.098447  1.000000 -0.049353 -0.056769 -0.197912  0.045032   \n",
       "cp       -0.068653 -0.049353  1.000000  0.047608 -0.076904  0.094444   \n",
       "trestbps  0.279351 -0.056769  0.047608  1.000000  0.123174  0.177531   \n",
       "chol      0.213678 -0.197912 -0.076904  0.123174  1.000000  0.013294   \n",
       "fbs       0.121308  0.045032  0.094444  0.177531  0.013294  1.000000   \n",
       "restecg  -0.116211 -0.058196  0.044421 -0.114103 -0.151040 -0.084189   \n",
       "thalach  -0.398522 -0.044020  0.295762 -0.046698 -0.009940 -0.008567   \n",
       "exang     0.096801  0.141664 -0.394280  0.067616  0.067023  0.025665   \n",
       "oldpeak   0.210013  0.096093 -0.149230  0.193216  0.053952  0.005747   \n",
       "slope    -0.168814 -0.030711  0.119717 -0.121475 -0.004038 -0.059894   \n",
       "ca        0.276326  0.118261 -0.181053  0.101389  0.070511  0.137979   \n",
       "thal      0.068001  0.210041 -0.161736  0.062210  0.098803 -0.032019   \n",
       "target   -0.225439 -0.280937  0.433798 -0.144931 -0.085239 -0.028046   \n",
       "\n",
       "           restecg   thalach     exang   oldpeak     slope        ca  \\\n",
       "age      -0.116211 -0.398522  0.096801  0.210013 -0.168814  0.276326   \n",
       "sex      -0.058196 -0.044020  0.141664  0.096093 -0.030711  0.118261   \n",
       "cp        0.044421  0.295762 -0.394280 -0.149230  0.119717 -0.181053   \n",
       "trestbps -0.114103 -0.046698  0.067616  0.193216 -0.121475  0.101389   \n",
       "chol     -0.151040 -0.009940  0.067023  0.053952 -0.004038  0.070511   \n",
       "fbs      -0.084189 -0.008567  0.025665  0.005747 -0.059894  0.137979   \n",
       "restecg   1.000000  0.044123 -0.070733 -0.058770  0.093045 -0.072042   \n",
       "thalach   0.044123  1.000000 -0.378812 -0.344187  0.386784 -0.213177   \n",
       "exang    -0.070733 -0.378812  1.000000  0.288223 -0.257748  0.115739   \n",
       "oldpeak  -0.058770 -0.344187  0.288223  1.000000 -0.577537  0.222682   \n",
       "slope     0.093045  0.386784 -0.257748 -0.577537  1.000000 -0.080155   \n",
       "ca       -0.072042 -0.213177  0.115739  0.222682 -0.080155  1.000000   \n",
       "thal     -0.011981 -0.096439  0.206754  0.210244 -0.104764  0.151832   \n",
       "target    0.137230  0.421741 -0.436757 -0.430696  0.345877 -0.391724   \n",
       "\n",
       "              thal    target  \n",
       "age       0.068001 -0.225439  \n",
       "sex       0.210041 -0.280937  \n",
       "cp       -0.161736  0.433798  \n",
       "trestbps  0.062210 -0.144931  \n",
       "chol      0.098803 -0.085239  \n",
       "fbs      -0.032019 -0.028046  \n",
       "restecg  -0.011981  0.137230  \n",
       "thalach  -0.096439  0.421741  \n",
       "exang     0.206754 -0.436757  \n",
       "oldpeak   0.210244 -0.430696  \n",
       "slope    -0.104764  0.345877  \n",
       "ca        0.151832 -0.391724  \n",
       "thal      1.000000 -0.344029  \n",
       "target   -0.344029  1.000000  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hd.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "altered-demonstration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...    ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786  1.0  273.0   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875  1.0  273.0   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675  1.0  273.0   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889  1.0  273.0   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030  80.8  2.5050  1.0  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  target  \n",
       "0       15.3  396.90   4.98    24.0  \n",
       "1       17.8  396.90   9.14    21.6  \n",
       "2       17.8  392.83   4.03    34.7  \n",
       "3       18.7  394.63   2.94    33.4  \n",
       "4       18.7  396.90   5.33    36.2  \n",
       "..       ...     ...    ...     ...  \n",
       "501     21.0  391.99   9.67    22.4  \n",
       "502     21.0  396.90   9.08    20.6  \n",
       "503     21.0  396.90   5.64    23.9  \n",
       "504     21.0  393.45   6.48    22.0  \n",
       "505     21.0  396.90   7.88    11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "animated-secretariat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CRIM</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.200469</td>\n",
       "      <td>0.406583</td>\n",
       "      <td>-0.055892</td>\n",
       "      <td>0.420972</td>\n",
       "      <td>-0.219247</td>\n",
       "      <td>0.352734</td>\n",
       "      <td>-0.379670</td>\n",
       "      <td>0.625505</td>\n",
       "      <td>0.582764</td>\n",
       "      <td>0.289946</td>\n",
       "      <td>-0.385064</td>\n",
       "      <td>0.455621</td>\n",
       "      <td>-0.388305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZN</th>\n",
       "      <td>-0.200469</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.533828</td>\n",
       "      <td>-0.042697</td>\n",
       "      <td>-0.516604</td>\n",
       "      <td>0.311991</td>\n",
       "      <td>-0.569537</td>\n",
       "      <td>0.664408</td>\n",
       "      <td>-0.311948</td>\n",
       "      <td>-0.314563</td>\n",
       "      <td>-0.391679</td>\n",
       "      <td>0.175520</td>\n",
       "      <td>-0.412995</td>\n",
       "      <td>0.360445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDUS</th>\n",
       "      <td>0.406583</td>\n",
       "      <td>-0.533828</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.062938</td>\n",
       "      <td>0.763651</td>\n",
       "      <td>-0.391676</td>\n",
       "      <td>0.644779</td>\n",
       "      <td>-0.708027</td>\n",
       "      <td>0.595129</td>\n",
       "      <td>0.720760</td>\n",
       "      <td>0.383248</td>\n",
       "      <td>-0.356977</td>\n",
       "      <td>0.603800</td>\n",
       "      <td>-0.483725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHAS</th>\n",
       "      <td>-0.055892</td>\n",
       "      <td>-0.042697</td>\n",
       "      <td>0.062938</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.091203</td>\n",
       "      <td>0.091251</td>\n",
       "      <td>0.086518</td>\n",
       "      <td>-0.099176</td>\n",
       "      <td>-0.007368</td>\n",
       "      <td>-0.035587</td>\n",
       "      <td>-0.121515</td>\n",
       "      <td>0.048788</td>\n",
       "      <td>-0.053929</td>\n",
       "      <td>0.175260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOX</th>\n",
       "      <td>0.420972</td>\n",
       "      <td>-0.516604</td>\n",
       "      <td>0.763651</td>\n",
       "      <td>0.091203</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.302188</td>\n",
       "      <td>0.731470</td>\n",
       "      <td>-0.769230</td>\n",
       "      <td>0.611441</td>\n",
       "      <td>0.668023</td>\n",
       "      <td>0.188933</td>\n",
       "      <td>-0.380051</td>\n",
       "      <td>0.590879</td>\n",
       "      <td>-0.427321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RM</th>\n",
       "      <td>-0.219247</td>\n",
       "      <td>0.311991</td>\n",
       "      <td>-0.391676</td>\n",
       "      <td>0.091251</td>\n",
       "      <td>-0.302188</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.240265</td>\n",
       "      <td>0.205246</td>\n",
       "      <td>-0.209847</td>\n",
       "      <td>-0.292048</td>\n",
       "      <td>-0.355501</td>\n",
       "      <td>0.128069</td>\n",
       "      <td>-0.613808</td>\n",
       "      <td>0.695360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE</th>\n",
       "      <td>0.352734</td>\n",
       "      <td>-0.569537</td>\n",
       "      <td>0.644779</td>\n",
       "      <td>0.086518</td>\n",
       "      <td>0.731470</td>\n",
       "      <td>-0.240265</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.747881</td>\n",
       "      <td>0.456022</td>\n",
       "      <td>0.506456</td>\n",
       "      <td>0.261515</td>\n",
       "      <td>-0.273534</td>\n",
       "      <td>0.602339</td>\n",
       "      <td>-0.376955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIS</th>\n",
       "      <td>-0.379670</td>\n",
       "      <td>0.664408</td>\n",
       "      <td>-0.708027</td>\n",
       "      <td>-0.099176</td>\n",
       "      <td>-0.769230</td>\n",
       "      <td>0.205246</td>\n",
       "      <td>-0.747881</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.494588</td>\n",
       "      <td>-0.534432</td>\n",
       "      <td>-0.232471</td>\n",
       "      <td>0.291512</td>\n",
       "      <td>-0.496996</td>\n",
       "      <td>0.249929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAD</th>\n",
       "      <td>0.625505</td>\n",
       "      <td>-0.311948</td>\n",
       "      <td>0.595129</td>\n",
       "      <td>-0.007368</td>\n",
       "      <td>0.611441</td>\n",
       "      <td>-0.209847</td>\n",
       "      <td>0.456022</td>\n",
       "      <td>-0.494588</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.910228</td>\n",
       "      <td>0.464741</td>\n",
       "      <td>-0.444413</td>\n",
       "      <td>0.488676</td>\n",
       "      <td>-0.381626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAX</th>\n",
       "      <td>0.582764</td>\n",
       "      <td>-0.314563</td>\n",
       "      <td>0.720760</td>\n",
       "      <td>-0.035587</td>\n",
       "      <td>0.668023</td>\n",
       "      <td>-0.292048</td>\n",
       "      <td>0.506456</td>\n",
       "      <td>-0.534432</td>\n",
       "      <td>0.910228</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.460853</td>\n",
       "      <td>-0.441808</td>\n",
       "      <td>0.543993</td>\n",
       "      <td>-0.468536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTRATIO</th>\n",
       "      <td>0.289946</td>\n",
       "      <td>-0.391679</td>\n",
       "      <td>0.383248</td>\n",
       "      <td>-0.121515</td>\n",
       "      <td>0.188933</td>\n",
       "      <td>-0.355501</td>\n",
       "      <td>0.261515</td>\n",
       "      <td>-0.232471</td>\n",
       "      <td>0.464741</td>\n",
       "      <td>0.460853</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.177383</td>\n",
       "      <td>0.374044</td>\n",
       "      <td>-0.507787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>-0.385064</td>\n",
       "      <td>0.175520</td>\n",
       "      <td>-0.356977</td>\n",
       "      <td>0.048788</td>\n",
       "      <td>-0.380051</td>\n",
       "      <td>0.128069</td>\n",
       "      <td>-0.273534</td>\n",
       "      <td>0.291512</td>\n",
       "      <td>-0.444413</td>\n",
       "      <td>-0.441808</td>\n",
       "      <td>-0.177383</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.366087</td>\n",
       "      <td>0.333461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTAT</th>\n",
       "      <td>0.455621</td>\n",
       "      <td>-0.412995</td>\n",
       "      <td>0.603800</td>\n",
       "      <td>-0.053929</td>\n",
       "      <td>0.590879</td>\n",
       "      <td>-0.613808</td>\n",
       "      <td>0.602339</td>\n",
       "      <td>-0.496996</td>\n",
       "      <td>0.488676</td>\n",
       "      <td>0.543993</td>\n",
       "      <td>0.374044</td>\n",
       "      <td>-0.366087</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.737663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>-0.388305</td>\n",
       "      <td>0.360445</td>\n",
       "      <td>-0.483725</td>\n",
       "      <td>0.175260</td>\n",
       "      <td>-0.427321</td>\n",
       "      <td>0.695360</td>\n",
       "      <td>-0.376955</td>\n",
       "      <td>0.249929</td>\n",
       "      <td>-0.381626</td>\n",
       "      <td>-0.468536</td>\n",
       "      <td>-0.507787</td>\n",
       "      <td>0.333461</td>\n",
       "      <td>-0.737663</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
       "CRIM     1.000000 -0.200469  0.406583 -0.055892  0.420972 -0.219247  0.352734   \n",
       "ZN      -0.200469  1.000000 -0.533828 -0.042697 -0.516604  0.311991 -0.569537   \n",
       "INDUS    0.406583 -0.533828  1.000000  0.062938  0.763651 -0.391676  0.644779   \n",
       "CHAS    -0.055892 -0.042697  0.062938  1.000000  0.091203  0.091251  0.086518   \n",
       "NOX      0.420972 -0.516604  0.763651  0.091203  1.000000 -0.302188  0.731470   \n",
       "RM      -0.219247  0.311991 -0.391676  0.091251 -0.302188  1.000000 -0.240265   \n",
       "AGE      0.352734 -0.569537  0.644779  0.086518  0.731470 -0.240265  1.000000   \n",
       "DIS     -0.379670  0.664408 -0.708027 -0.099176 -0.769230  0.205246 -0.747881   \n",
       "RAD      0.625505 -0.311948  0.595129 -0.007368  0.611441 -0.209847  0.456022   \n",
       "TAX      0.582764 -0.314563  0.720760 -0.035587  0.668023 -0.292048  0.506456   \n",
       "PTRATIO  0.289946 -0.391679  0.383248 -0.121515  0.188933 -0.355501  0.261515   \n",
       "B       -0.385064  0.175520 -0.356977  0.048788 -0.380051  0.128069 -0.273534   \n",
       "LSTAT    0.455621 -0.412995  0.603800 -0.053929  0.590879 -0.613808  0.602339   \n",
       "target  -0.388305  0.360445 -0.483725  0.175260 -0.427321  0.695360 -0.376955   \n",
       "\n",
       "              DIS       RAD       TAX   PTRATIO         B     LSTAT    target  \n",
       "CRIM    -0.379670  0.625505  0.582764  0.289946 -0.385064  0.455621 -0.388305  \n",
       "ZN       0.664408 -0.311948 -0.314563 -0.391679  0.175520 -0.412995  0.360445  \n",
       "INDUS   -0.708027  0.595129  0.720760  0.383248 -0.356977  0.603800 -0.483725  \n",
       "CHAS    -0.099176 -0.007368 -0.035587 -0.121515  0.048788 -0.053929  0.175260  \n",
       "NOX     -0.769230  0.611441  0.668023  0.188933 -0.380051  0.590879 -0.427321  \n",
       "RM       0.205246 -0.209847 -0.292048 -0.355501  0.128069 -0.613808  0.695360  \n",
       "AGE     -0.747881  0.456022  0.506456  0.261515 -0.273534  0.602339 -0.376955  \n",
       "DIS      1.000000 -0.494588 -0.534432 -0.232471  0.291512 -0.496996  0.249929  \n",
       "RAD     -0.494588  1.000000  0.910228  0.464741 -0.444413  0.488676 -0.381626  \n",
       "TAX     -0.534432  0.910228  1.000000  0.460853 -0.441808  0.543993 -0.468536  \n",
       "PTRATIO -0.232471  0.464741  0.460853  1.000000 -0.177383  0.374044 -0.507787  \n",
       "B        0.291512 -0.444413 -0.441808 -0.177383  1.000000 -0.366087  0.333461  \n",
       "LSTAT   -0.496996  0.488676  0.543993  0.374044 -0.366087  1.000000 -0.737663  \n",
       "target   0.249929 -0.381626 -0.468536 -0.507787  0.333461 -0.737663  1.000000  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ruled-barcelona",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
